{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_LAYER_NEURONS = 10\n",
    "OUTPUT_LAYER_NEURONS = 10\n",
    "\n",
    "input_file_path = \"../Training/model_weights.txt\"  # Update this path to your weights file\n",
    "output_directory = \"./Hidden_Neuron_Weights/\"  # Update this path to your desired output directory\n",
    "\n",
    "dataWidth = 16\n",
    "weightIntWidth = 3\n",
    "\n",
    "outPATH = \"Binary_Rep/\"\n",
    "inputFile = \"Hidden_Neuron_Weights/\"\n",
    "\n",
    "mnist_input_file_path = 'Input_Bin/mnist_normalized_line_by_line.txt'\n",
    "mnist_output_txt_path = 'Input_Bin/bin_mnist_normalized_line_by_line.txt'\n",
    "mnist_output_bat_path = 'Input_Bin/bin_mnist_normalized_line_by_line.bat'\n",
    "\n",
    "weightFracWidth = dataWidth - weightIntWidth\n",
    "print(weightFracWidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utils Function for Separate All of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weight_line(line):\n",
    "    \"\"\"\n",
    "    Parse a line from the weight file and extract the layer, source neuron,\n",
    "    destination neuron, and weight value. Adjusted to handle commas.\n",
    "    \"\"\"\n",
    "    parts = line.replace(',', '').split()  # Remove commas before splitting\n",
    "    layer = int(parts[2])\n",
    "    source_neuron = int(parts[4])\n",
    "    dest_neuron = int(parts[9])\n",
    "    weight = float(parts[-1])\n",
    "    return layer, source_neuron, dest_neuron, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_weights(input_file, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if(not os.path.exists(output_dir)):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Adjust initialization to include neuron '0'\n",
    "    neuron_weights = {'hidden': {i: [] for i in range(0, HIDDEN_LAYER_NEURONS + 1)},\n",
    "                      'output': {i: [] for i in range(0, OUTPUT_LAYER_NEURONS + 1)}}\n",
    "    \n",
    "    # Read and parse the input file\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            layer, source_neuron, dest_neuron, weight = parse_weight_line(line)       \n",
    "            neuron_type = 'hidden' if layer == 1 else 'output'\n",
    "            neuron_weights[neuron_type][dest_neuron].append((source_neuron, weight))\n",
    "    \n",
    "    # Write weights to separate files\n",
    "    for neuron_type, neurons in neuron_weights.items():\n",
    "        for neuron_id, weights in neurons.items():\n",
    "            file_name = f\"{neuron_type}_neuron_{neuron_id}_weights.txt\"\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            with open(file_path, 'w') as f:\n",
    "                for source_neuron, weight in weights:\n",
    "                    f.write(f\"{weight}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Spare Weights File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribute_weights(input_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convert Weights to the Binary Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. To Binary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DtoB(num, dataWidth, fracBits):\n",
    "    if(num >= 0):\n",
    "        num = num * (2 ** fracBits)\n",
    "    else:\n",
    "        num = (num + 2**(dataWidth + fracBits)) * (2 ** fracBits)\n",
    "    num = int(num) & (2 ** dataWidth - 1)\n",
    "    return format(num, '0{}b'.format(dataWidth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden_neuron_0_weights.txt',\n",
       " 'hidden_neuron_10_weights.txt',\n",
       " 'hidden_neuron_1_weights.txt',\n",
       " 'hidden_neuron_2_weights.txt',\n",
       " 'hidden_neuron_3_weights.txt',\n",
       " 'hidden_neuron_4_weights.txt',\n",
       " 'hidden_neuron_5_weights.txt',\n",
       " 'hidden_neuron_6_weights.txt',\n",
       " 'hidden_neuron_7_weights.txt',\n",
       " 'hidden_neuron_8_weights.txt',\n",
       " 'hidden_neuron_9_weights.txt',\n",
       " 'output_neuron_0_weights.txt',\n",
       " 'output_neuron_10_weights.txt',\n",
       " 'output_neuron_1_weights.txt',\n",
       " 'output_neuron_2_weights.txt',\n",
       " 'output_neuron_3_weights.txt',\n",
       " 'output_neuron_4_weights.txt',\n",
       " 'output_neuron_5_weights.txt',\n",
       " 'output_neuron_6_weights.txt',\n",
       " 'output_neuron_7_weights.txt',\n",
       " 'output_neuron_8_weights.txt',\n",
       " 'output_neuron_9_weights.txt']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in os.listdir(inputFile) if f.endswith('.txt')]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Convert All Weights to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and saved in 'Binary_Rep/txt/' directory.\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    input_file_path = os.path.join(inputFile, file)\n",
    "    output_file_path = os.path.join(outPATH + \"txt/\", f\"bin_{file}\")\n",
    "    \n",
    "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            num = float(line.strip())  # Read and convert each line to a float\n",
    "            binary_rep = DtoB(num, dataWidth, weightFracWidth)  # Convert to binary\n",
    "            outfile.write(binary_rep + '\\n')  # Write the binary representation to the output file\n",
    "\n",
    "print(\"All files have been processed and saved in 'Binary_Rep/txt/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Save Weights With `.bat` Format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been processed and saved in 'Binary_Rep/bat/' directory with .bat format.\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    input_file_path = os.path.join(inputFile, file)\n",
    "    output_file_path = os.path.join(outPATH + \"bat/\", f\"bin_{os.path.splitext(file)[0]}.bat\")  # Save as .bat\n",
    "    \n",
    "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            num = float(line.strip())  # Read and convert each line to a float\n",
    "            binary_rep = DtoB(num, dataWidth, weightFracWidth)  # Convert to binary\n",
    "            outfile.write(binary_rep + '\\n')  # Write the binary representation to the output file\n",
    "\n",
    "print(\"All files have been processed and saved in 'Binary_Rep/bat/' directory with .bat format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Read 20 Test Input and Convert to The Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Read and Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Input_Bin/mnist_normalized_line_by_line.txt\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "# Select the first 20 instances and normalize them\n",
    "x_train_selected = x_train[:20] / 255.0\n",
    "\n",
    "# Prepare the content to be saved in a text file\n",
    "content = \"\"\n",
    "for i in range(20):\n",
    "    content += f\"Image {i+1}: True class = {y_train[i]}\\n\"\n",
    "    flattened = x_train_selected[i].flatten()  # Flatten the 28x28 image to a 1D array of 784 elements\n",
    "    for pixel in flattened:\n",
    "        content += f\"{pixel:.6f}\\n\"\n",
    "    content += \"\\n\"  # Separate instances with a newline for clarity\n",
    "\n",
    "# Save the content to a text file\n",
    "file_path = 'Input_Bin/mnist_normalized_line_by_line.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"Data saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Convert to the Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary data saved to Input_Bin/bin_mnist_normalized_line_by_line.txt and Input_Bin/bin_mnist_normalized_line_by_line.bat\n"
     ]
    }
   ],
   "source": [
    "# Read the input file, process the pixel values, and save to the output files\n",
    "with open(mnist_input_file_path, 'r') as infile, \\\n",
    "     open(mnist_output_txt_path, 'w') as outfile_txt, \\\n",
    "     open(mnist_output_bat_path, 'w') as outfile_bat:\n",
    "\n",
    "    for line in infile:\n",
    "        if \"Image\" in line or \"True class\" in line:\n",
    "            outfile_txt.write(line)  # Copy over the \"Image\" and \"True class\" lines to .txt\n",
    "            outfile_bat.write(line)  # Copy over the \"Image\" and \"True class\" lines to .bat\n",
    "        elif line.strip():  # Process pixel values if the line isn't empty\n",
    "            pixel_value = float(line.strip())\n",
    "            binary_rep = DtoB(pixel_value, dataWidth, weightFracWidth)  # Convert to binary\n",
    "            outfile_txt.write(binary_rep + '\\n')  # Write binary representation to .txt\n",
    "            outfile_bat.write(binary_rep + '\\n')  # Write binary representation to .bat\n",
    "\n",
    "print(f\"Binary data saved to {mnist_output_txt_path} and {mnist_output_bat_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
